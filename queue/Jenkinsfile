// Jenkinsfile (Dispatcher)
// - Orchestrates a 4-leg matrix (AGENT=agent-1..agent-4) from the controller
// - Central JSON queue on controller using a filesystem mutex (no extra plugins)
// - Each leg dispatches to its exact worker by passing NODE_LABEL=<AGENT>
// - Downstream builds are async to avoid single-executor deadlocks
// - BUILD_BY populated via sandbox-safe getBuildCauses('UserIdCause')

pipeline {
  // Change to 'master' if your controller label is 'master'
  agent { label 'built-in' }

  options {
    timestamps()
    disableConcurrentBuilds()
    buildDiscarder(logRotator(numToKeepStr: '10')) // keep last 10 builds
  }

  parameters {
    string(name: 'BATCH_JSON',  defaultValue: '', description: 'Raw JSON payload from scheduler (e.g., {"jobs":[...]}).')
    string(name: 'SOURCE',      defaultValue: '', description: 'every_15m | hourly | daily | weekly')
    string(name: 'IDLE_ROUNDS', defaultValue: '24', description: 'Worker idle checks (5s each) before exit; 24 ≈ 2 min.')
  }

  environment {
    // Where queue file lives; dispatcher also runs here
    QUEUE_NODE     = 'built-in'     // change to 'master' if needed
    DISPATCH_LABEL = 'built-in'     // matrix legs run here (not on workers)

    // Path for queue file on QUEUE_NODE (this job’s workspace on that node)
    QUEUE_DIR  = 'queue-shared'
    QUEUE_FILE = 'queue.json'
    LOCK_DIR   = '.lock'            // mkdir-based mutex
    BUILD_BY   = ''                 // set in Init
  }

  stages {
    stage('Init') {
      steps {
        script {
          def uc = currentBuild.getBuildCauses('hudson.model.Cause$UserIdCause')
          env.BUILD_BY = (uc && !uc.isEmpty()) ? (uc[0].userName ?: 'SYSTEM') : 'SYSTEM'
          echo "Build triggered by: ${env.BUILD_BY}"
        }
      }
    }

    stage('Ingest batch') {
      when { expression { return params.BATCH_JSON?.trim() } }
      steps {
        script {
          echo "Ingesting batch from source='${params.SOURCE}' (size=${params.BATCH_JSON.length()})"
          withCentralQueue {
            def qText = fileExists(env.QUEUE_FILE) ? readFile(env.QUEUE_FILE) : '{"jobs":[],"deadLetter":[]}'
            def merged = safeMerge(qText, params.BATCH_JSON, params.SOURCE)
            writeFile file: env.QUEUE_FILE, text: groovy.json.JsonOutput.prettyPrint(merged)
          }
          echo "Queue updated at ${env.QUEUE_NODE}:${env.QUEUE_DIR}/${env.QUEUE_FILE}"
        }
      }
    }

    stage('workflow') {
      matrix {
        axes {
          axis {
            name 'AGENT' // exact labels of your four workers
            values 'agent-1', 'agent-2', 'agent-3', 'agent-4'
          }
        }

        // Run dispatchers on controller (or a tiny dispatcher node), not on workers
        agent { label env.DISPATCH_LABEL }

        stages {
          stage('work') {
            steps {
              script {
                echo "Dispatcher leg for ${AGENT} (controller node: ${env.NODE_NAME}, by ${env.BUILD_BY})"
                workerLoop(env.BUILD_BY, AGENT as String, (params.IDLE_ROUNDS ?: '24') as int)
              }
            }
          }
        }
      }
    }
  }

  post {
    always {
      echo "Done. Built by ${env.BUILD_BY}"
    }
  }
}

/* ============================ Worker Logic ============================ */

def workerLoop(String buildBy, String tokenId, int maxIdleRounds) {
  int idleRounds = 0

  while (true) {
    def jobItem = claimOne(tokenId)   // atomic claim on QUEUE_NODE

    if (jobItem == null) {
      idleRounds++
      if (idleRounds >= Math.max(1, maxIdleRounds)) {
        echo "[${tokenId}] No jobs after ${idleRounds} checks. Exiting."
        break
      }
      sleep time: 5, unit: 'SECONDS'
      continue
    }

    idleRounds = 0

    // ---- Execute outside queue critical section ----
    def jobName  = jobItem.job?.toString()
    def params   = buildParams(jobItem.parameters)

    // Route job to exact worker matching this token
    params += [ string(name: 'NODE_LABEL', value: tokenId) ]

    echo "[${tokenId}] ▶ DISPATCH ${jobItem.name} src=${jobItem.source} -> ${jobName} (prio=${jobItem.priority}, attempt=${jobItem.attempts}, by=${buildBy})"

    boolean ok = true
    String errMsg = null
    try {
      // Always async to avoid deadlocks on single-executor workers
      build job: jobName, wait: false, propagate: true, parameters: params
      echo "[${tokenId}] ✔ DISPATCHED ${jobItem.name}"
    } catch (e) {
      ok = false
      errMsg = e.getMessage()
      echo "[${tokenId}] ✖ DISPATCH FAIL ${jobItem.name} : ${errMsg}"
    }

    finalizeOne(jobItem, ok, errMsg, tokenId)  // atomic finalize on QUEUE_NODE
  }
}

/* ===================== Central queue helpers (no plugins) ===================== */

def withCentralQueue(Closure body) {
  node(env.QUEUE_NODE) {
    dir(env.QUEUE_DIR) {
      if (!fileExists(env.QUEUE_FILE)) {
        writeFile file: env.QUEUE_FILE, text: '{"jobs":[],"deadLetter":[]}'
      }
      withFsMutex {
        body.call()
      }
    }
  }
}

def claimOne(String tokenId) {
  def claimed = null
  withCentralQueue {
    def qText = readFile(env.QUEUE_FILE)
    def q = parsePlainSafe(qText) ?: [jobs:[], deadLetter:[]]
    if (!(q.jobs instanceof List)) q.jobs = []
    if (!(q.deadLetter instanceof List)) q.deadLetter = []

    // Priority desc, FIFO by receivedAt
    q.jobs.sort { a, b ->
      int pa = (a.priority ?: 0) as int
      int pb = (b.priority ?: 0) as int
      def byPrio = (pb <=> pa)
      if (byPrio != 0) return byPrio
      (a.receivedAt ?: '') <=> (b.receivedAt ?: '')
    }

    int idx = q.jobs.findIndexOf { it.status == null || it.status == 'queued' }
    if (idx != -1) {
      claimed = q.jobs[idx]
      claimed.status    = 'running'
      claimed.processor = tokenId
      claimed.attempts  = ((claimed.attempts ?: 0) as int) + 1
      writeFile file: env.QUEUE_FILE, text: groovy.json.JsonOutput.prettyPrint(
        toJsonString([jobs:q.jobs, deadLetter:q.deadLetter])
      )
    }
  }
  return claimed
}

def finalizeOne(def jobItem, boolean ok, String errMsg, String tokenId) {
  withCentralQueue {
    def qText = readFile(env.QUEUE_FILE)
    def q = parsePlainSafe(qText) ?: [jobs:[], deadLetter:[]]
    if (!(q.jobs instanceof List)) q.jobs = []
    if (!(q.deadLetter instanceof List)) q.deadLetter = []

    int idx2 = q.jobs.findIndexOf {
      it.name?.toString()   == jobItem.name?.toString() &&
      (it.receivedAt ?: '') == (jobItem.receivedAt ?: '') &&
      (it.processor ?: '')  == tokenId &&
      (it.status ?: '')     == 'running'
    }

    if (idx2 == -1) {
      echo "[${tokenId}] WARN: Claimed item not found during finalize."
      if (!ok) { (q.deadLetter as List) << (jobItem + [status:'failed', error:(errMsg ?: 'unknown')]) }
    } else {
      def running = q.jobs.remove(idx2)
      if (ok) {
        // success: drop
      } else {
        int attempts = (running.attempts ?: 1) as int
        if (attempts >= 3) {
          running.status = 'failed'
          running.error  = errMsg
          (q.deadLetter as List) << running
        } else {
          running.status    = 'queued'
          running.processor = null
          q.jobs << running   // requeue; fairness kept by resort during next claim
        }
      }
    }

    writeFile file: env.QUEUE_FILE, text: groovy.json.JsonOutput.prettyPrint(
      toJsonString([jobs:q.jobs, deadLetter:q.deadLetter])
    )
  }
}

/* ============================ Filesystem mutex ============================ */

def withFsMutex(Closure body) {
  int attempts = 0, maxAttempts = 120
  try {
    while (true) {
      int code = isUnix()
        ? sh(script: "mkdir '${env.LOCK_DIR}' 2>/dev/null && exit 0 || exit 1", returnStatus: true)
        : powershell(returnStatus: true, script: """
            try { New-Item -ItemType Directory -Path '${env.LOCK_DIR}' -ErrorAction Stop | Out-Null; exit 0 }
            catch { exit 1 }
          """.stripIndent())
      if (code == 0) break
      if (++attempts >= maxAttempts) error "Could not acquire queue mutex at ${pwd()}/${env.LOCK_DIR}"
      sleep time: 1, unit: 'SECONDS'
    }
    body.call()
  } finally {
    if (isUnix()) {
      sh script: "rm -rf '${env.LOCK_DIR}' || true"
    } else {
      powershell script: "Remove-Item -LiteralPath '${env.LOCK_DIR}' -Force -Recurse -ErrorAction SilentlyContinue"
    }
  }
}

/* ============================ JSON & Params ============================ */

def buildParams(List plist) {
  def m = [:]
  (plist ?: []).each { kv ->
    if (kv?.name) m[kv.name.toString()] = (kv.value == null ? '' : kv.value.toString())
  }
  return [
    string(name: 'PARAM1', value: m['PARAM1'] ?: ''),
    string(name: 'PARAM2', value: m['PARAM2'] ?: ''),
    string(name: 'PARAM3', value: m['PARAM3'] ?: ''),
    string(name: 'PARAM4', value: m['PARAM4'] ?: '')
  ]
}

@NonCPS
def safeMerge(String existingText, String batchText, String source) {
  def existing = parsePlainSafe(existingText) ?: [jobs: [], deadLetter: []]
  if (!(existing.jobs instanceof List)) existing.jobs = []
  if (!(existing.deadLetter instanceof List)) existing.deadLetter = []

  def batch = parsePlainSafe(batchText) ?: [jobs: []]
  def now = new Date().format("yyyy-MM-dd'T'HH:mm:ssXXX")

  (batch.jobs ?: []).each { j ->
    def item = toPlain(j) ?: [:]
    if (!(item.parameters instanceof List)) item.parameters = []
    item.source     = source?.toString()
    item.receivedAt = now
    item.status     = 'queued'
    item.attempts   = 0
    existing.jobs << item
  }

  return groovy.json.JsonOutput.toJson(existing)
}

@NonCPS
def parsePlainSafe(String jsonText) {
  if (!jsonText) return null
  def t = jsonText.trim()
  if (t.length() == 0) return null
  try {
    def p = new groovy.json.JsonSlurper().parseText(t)
    return toPlain(p)
  } catch (Throwable ignored) {
    return null
  }
}

@NonCPS
def toPlain(Object o) {
  if (o instanceof Map)  { def m = [:]; o.each { k,v -> m[(k?.toString())] = toPlain(v) }; return m }
  if (o instanceof List) { def l = [];  o.each { v -> l << toPlain(v) }; return l }
  return o
}

@NonCPS
def toJsonString(Object o) { groovy.json.JsonOutput.toJson(o) }
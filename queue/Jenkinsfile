pipeline {
  agent { label 'master' }

  parameters {
    string(name: 'ListOfJobs', defaultValue: '', description: 'Upstream JSON payload ({"jobs":[...]}) or []')
    booleanParam(name: 'PURGE_QUEUE', defaultValue: false, description: 'Wipe queue.json (fresh start).')
    booleanParam(name: 'PURGE_DEADLETTER', defaultValue: false, description: 'Clear deadLetter only.')
    booleanParam(name: 'REQUEUE_DEADLETTER', defaultValue: false, description: 'Requeue DLQ items with attempts=0.')
    string(name: 'MAX_LIVE', defaultValue: '4', description: 'Max live jobs per cycle (≤ live tokens).')
    string(name: 'MAX_STAGING', defaultValue: '4', description: 'Max staging jobs per cycle (≤ staging tokens).')
    string(name: 'RETRY_LIMIT', defaultValue: '3', description: 'Max attempts before moving to deadLetter.')
    string(name: 'IDLE_SLEEP', defaultValue: '15', description: 'Seconds to sleep when nothing to claim.')
  }

  options {
    timestamps()
    buildDiscarder(logRotator(numToKeepStr: '30', daysToKeepStr: '30'))
    // Keep this commented if you want "ingest while running" from other upstream builds.
    // disableConcurrentBuilds()
  }

  environment {
    QUEUE_PATH = 'queue.json'
    LIVE_LABEL = 'api-token-live'
    STG_LABEL  = 'api-token-staging'
  }

  stages {

    stage('Optional: Purge / DLQ Ops') {
      when { expression { params.PURGE_QUEUE || params.PURGE_DEADLETTER || params.REQUEUE_DEADLETTER } }
      steps {
        script {
          lock(resource: 'queue-json') {
            def cur = ensureQueueFile()
            if (params.PURGE_QUEUE) {
              cur.jobs = []; cur.deadLetter = []
              echo 'Queue + DeadLetter wiped.'
            } else if (params.PURGE_DEADLETTER) {
              cur.deadLetter = []
              echo 'DeadLetter wiped.'
            }
            if (params.REQUEUE_DEADLETTER) {
              def nowIso = isoNow()
              int moved = 0
              (cur.deadLetter as List).each { j ->
                def x = toPlain(j)
                x.status    = 'queued'
                x.attempts  = 0
                x.claimId   = null
                x.startedAt = null
                x.receivedAt = x.receivedAt ?: nowIso
                if (!(x.parameters instanceof List)) x.parameters = []
                (cur.jobs as List) << x
                moved++
              }
              cur.deadLetter = []
              cur.jobs = sortJobs(cur.jobs as List)
              echo "Requeued ${moved} item(s) from deadLetter."
            }
            writeQueue(cur)
          }
        }
      }
    }

    stage('Initial Ingest (ListOfJobs)') {
      steps {
        script {
          if (!params.ListOfJobs?.trim()) {
            echo 'No ListOfJobs provided; skipping initial ingest.'
            return
          }
          lock(resource: 'queue-json') {
            def cur = ensureQueueFile()
            def incoming = parseJobsToPlain(params.ListOfJobs)
            def nowIso = isoNow()
            int added = 0
            (incoming.jobs ?: []).each { j ->
              def item = toPlain(j) ?: [:]
              if (!(item.parameters instanceof List)) item.parameters = []
              // normalize env from parameters; default staging if missing
              def envParam = item.parameters.find { it?.name?.toString() == 'env' }
              def envValue = envParam?.value?.toString()?.toLowerCase()
              if (!envValue) {
                envValue = 'staging'
                item.parameters << [name:'env', value: envValue]
              }
              item.env       = envValue
              item.status    = 'queued'
              item.attempts  = (item.attempts ?: 0) as int
              item.receivedAt = item.receivedAt ?: nowIso
              if (!item.job) {
                item.error = 'missing job name (ingest)'
                (cur.deadLetter as List) << item
              } else {
                (cur.jobs as List) << item
                added++
              }
            }
            cur.jobs = sortJobs(cur.jobs as List)
            writeQueue(cur)
            echo "Queue updated: added=${added}, totalQueued=${(cur.jobs as List).count{ it.status=='queued' }}, deadLetter=${(cur.deadLetter as List).size()}"
          }
        }
      }
    }

    stage('Drain queue (live & staging token pools)') {
      steps {
        script {
          int maxLive    = safeInt(params.MAX_LIVE, 4)
          int maxStaging = safeInt(params.MAX_STAGING, 4)
          int retryLimit = safeInt(params.RETRY_LIMIT, 3)
          int idleSleep  = safeInt(params.IDLE_SLEEP, 15)

          while (true) {
            List liveClaims = []
            List stgClaims  = []

            // 1) CLAIM on master, separate by env
            lock(resource: 'queue-json') {
              def cur = ensureQueueFile()
              cur.jobs = sortJobs(cur.jobs as List)

              def queuedLive = (cur.jobs as List).findAll { (it.status ?: 'queued') == 'queued' && (it.env ?: 'staging') == 'live' }
              def queuedStg  = (cur.jobs as List).findAll { (it.status ?: 'queued') == 'queued' && (it.env ?: 'staging') == 'staging' }

              liveClaims = queuedLive.take(maxLive).collect { toPlain(it) }
              stgClaims  = queuedStg.take(maxStaging).collect { toPlain(it) }

              if (!liveClaims && !stgClaims) {
                writeQueue(cur)
              } else {
                String liveId = UUID.randomUUID().toString()
                String stgId  = UUID.randomUUID().toString()
                String nowIso = isoNow()

                liveClaims.each { c ->
                  int idx = (cur.jobs as List).findIndexOf { j ->
                    (j?.job?.toString() == c.job?.toString()) &&
                    ((j?.name?.toString() ?: '') == (c.name?.toString() ?: '')) &&
                    (j?.receivedAt?.toString() == c.receivedAt?.toString()) &&
                    ((j?.status ?: 'queued') == 'queued') &&
                    ((j?.env ?: 'staging') == 'live')
                  }
                  if (idx >= 0) {
                    cur.jobs[idx].status    = 'running'
                    cur.jobs[idx].claimId   = liveId
                    cur.jobs[idx].startedAt = nowIso
                    c.status    = 'running'
                    c.claimId   = liveId
                    c.startedAt = nowIso
                  }
                }

                stgClaims.each { c ->
                  int idx = (cur.jobs as List).findIndexOf { j ->
                    (j?.job?.toString() == c.job?.toString()) &&
                    ((j?.name?.toString() ?: '') == (c.name?.toString() ?: '')) &&
                    (j?.receivedAt?.toString() == c.receivedAt?.toString()) &&
                    ((j?.status ?: 'queued') == 'queued') &&
                    ((j?.env ?: 'staging') == 'staging')
                  }
                  if (idx >= 0) {
                    cur.jobs[idx].status    = 'running'
                    cur.jobs[idx].claimId   = stgId
                    cur.jobs[idx].startedAt = nowIso
                    c.status    = 'running'
                    c.claimId   = stgId
                    c.startedAt = nowIso
                  }
                }

                writeQueue(cur)
              }
            } // lock queue-json

            // If nothing to claim, brief idle; exit if truly drained
            if (!liveClaims && !stgClaims) {
              echo "Nothing to claim; sleeping ${idleSleep}s..."
              sleep(time: idleSleep, unit: 'SECONDS')
              boolean drained = false
              lock(resource: 'queue-json') {
                def cur = ensureQueueFile()
                int q = (cur.jobs as List).count { it.status == 'queued' }
                int r = (cur.jobs as List).count { it.status == 'running' }
                drained = (q == 0 && r == 0)
              }
              if (drained) {
                echo 'Queue fully drained. Exiting.'
                break
              }
              continue
            }

            echo "Claimed live=${liveClaims.size()}, staging=${stgClaims.size()} this cycle."

            // 2) RUN both pools in parallel; each branch locks from the correct label
            def branches = [:]

            for (int i = 0; i < liveClaims.size(); i++) {
              def item = liveClaims[i]
              branches["live-${i}-${item.name ?: item.job}"] = {
                lock(label: env.LIVE_LABEL, quantity: 1) {
                  runAndFinalize(item, retryLimit)
                }
              }
            }

            for (int i = 0; i < stgClaims.size(); i++) {
              def item = stgClaims[i]
              branches["stg-${i}-${item.name ?: item.job}"] = {
                lock(label: env.STG_LABEL, quantity: 1) {
                  runAndFinalize(item, retryLimit)
                }
              }
            }

            parallel branches
            // loop continues to next batch
          } // while
        } // script
      } // steps
    } // stage
  } // stages

  post {
    always {
      script {
        if (fileExists(env.QUEUE_PATH)) {
          def cur = parsePlainSafe(readFile(env.QUEUE_PATH)) ?: [jobs:[], deadLetter:[]]
          echo "Final queue: queued=${(cur.jobs as List).count{ it.status=='queued' }}, running=${(cur.jobs as List).count{ it.status=='running' }}, deadLetter=${(cur.deadLetter as List).size()}"
          echo "Remaining jobs: " + (cur.jobs as List).collect{ it.name ?: it.job }.join(', ')
        }
      }
    }
  }
}

/* ---------------- Helpers ---------------- */

def runAndFinalize(item, int retryLimit) {
  def jobName = item.job.toString()
  def plist   = (item.parameters ?: []).collect { kv ->
    string(name: kv.name.toString(), value: (kv.value == null ? '' : kv.value.toString()))
  }

  boolean ok = true
  String err = null
  try {
    echo "▶ RUN ${item.env ?: 'staging'} :: ${item.name ?: jobName} (prio=${item.priority ?: 0})"
    build job: jobName, wait: true, propagate: true, parameters: plist
    echo "✔ DONE ${item.name ?: jobName}"
  } catch (e) {
    ok = false
    err = e.getMessage()
    echo "✖ FAIL ${item.name ?: jobName}: ${err}"
  }

  lock(resource: 'queue-json') {
    def cur = ensureQueueFile()
    int idx = (cur.jobs as List).findIndexOf { j ->
      (j?.status == 'running') &&
      (j?.claimId?.toString() == item.claimId?.toString()) &&
      (j?.job?.toString() == jobName) &&
      ((j?.name?.toString() ?: '') == (item.name?.toString() ?: ''))
    }
    if (idx >= 0) {
      def j = cur.jobs[idx]
      if (ok) {
        cur.jobs.remove(idx)
      } else {
        int attempts = ((j.attempts ?: 0) as int) + 1
        j.attempts = attempts
        if (attempts >= retryLimit) {
          j.status = 'failed'
          j.error  = err ?: 'unknown'
          (cur.deadLetter as List) << j
          cur.jobs.remove(idx)
        } else {
          j.status    = 'queued'
          j.claimId   = null
          j.startedAt = null
          cur.jobs[idx] = j
        }
      }
      writeQueue(cur)
    } else {
      echo "WARN: Claimed item not found during finalize."
    }
  }
}

@NonCPS
def parseJobsToPlain(String raw) {
  def sl = new groovy.json.JsonSlurper()
  Object obj
  try { obj = sl.parseText(raw?.trim()) } catch (e) {
    throw new Exception("Invalid JSON (${e.message}). First 200 chars: ${raw?.take(200)}")
  }
  if (obj instanceof String) obj = sl.parseText(obj)
  if (obj instanceof List)   obj = [jobs: obj]
  else if (!(obj instanceof Map) || !(obj.jobs instanceof List))
    throw new Exception('Expected top-level {"jobs":[...]} or a bare array.')
  return toPlain(obj)
}

@NonCPS
def parsePlainSafe(String text) {
  if (!text) return null
  try {
    def p = new groovy.json.JsonSlurper().parseText(text.trim())
    if (p instanceof String) p = new groovy.json.JsonSlurper().parseText(p)
    return toPlain(p)
  } catch (ignored) { return null }
}

@NonCPS
def toPlain(Object o) {
  if (o instanceof Map)  { def m = [:]; o.each { k,v -> m[(k?.toString())] = toPlain(v) }; return m }
  if (o instanceof List) { return o.collect { toPlain(it) } }
  return o
}

@NonCPS
def sortJobs(List jobs) {
  if (!(jobs instanceof List)) return []
  def copy = jobs.collect { toPlain(it) }
  copy.sort { a, b ->
    int pa = ((a?.priority) ?: 0) as int
    int pb = ((b?.priority) ?: 0) as int
    def cmp = (pb <=> pa)  // higher priority first
    if (cmp != 0) return cmp
    String ra = (a?.receivedAt ?: '')
    String rb = (b?.receivedAt ?: '')
    return (ra <=> rb)     // FIFO within same priority
  }
  return copy
}

def ensureQueueFile() {
  if (!fileExists(env.QUEUE_PATH)) {
    writeFile file: env.QUEUE_PATH, text: '{"jobs":[],"deadLetter":[]}'
  }
  def cur = parsePlainSafe(readFile(env.QUEUE_PATH)) ?: [jobs: [], deadLetter: []]
  if (!(cur.jobs instanceof List))       cur.jobs = []
  if (!(cur.deadLetter instanceof List)) cur.deadLetter = []
  return cur
}

def writeQueue(cur) {
  writeFile file: env.QUEUE_PATH,
            text: groovy.json.JsonOutput.prettyPrint(groovy.json.JsonOutput.toJson(cur))
}

@NonCPS
def isoNow() {
  return new Date().format("yyyy-MM-dd'T'HH:mm:ssXXX")
}

@NonCPS
def safeInt(def s, int dflt) {
  try { return (s as String)?.trim()?.isInteger() ? (s as int) : dflt } catch (ignored) { return dflt }
}

/*
  Queue is centralized on one node (usually the controller/built-in),
  and all reads/writes happen there under a simple filesystem mutex.
  No Lockable Resources plugin needed.

  Setup:
    1) Make sure the QUEUE_NODE exists (built-in is fine).
    2) Ensure QUEUE_DIR exists or let this job create it (it writes there).
*/

def QUEUE_NODE = 'built-in'                 // or label of a dedicated fileshare node
def QUEUE_DIR  = 'queue-shared'             // folder under that node's workspace
def QUEUE_FILE = 'queue.json'
def LOCK_DIR   = '.lock'                    // fs mutex dir inside QUEUE_DIR

pipeline {
  agent any
  options { timestamps(); disableConcurrentBuilds() }

  parameters {
    string(name: 'BATCH_JSON',  defaultValue: '', description: 'Raw JSON payload from scheduler (jobs array).')
    string(name: 'SOURCE',      defaultValue: '', description: 'every_15m | hourly | daily | weekly')
    string(name: 'IDLE_ROUNDS', defaultValue: '24', description: 'How many 5s idle checks before a worker leg exits.')
  }

  stages {
    stage('Ingest batch') {
      when { expression { return params.BATCH_JSON?.trim() } }
      steps {
        script {
          echo "Ingesting batch from source='${params.SOURCE}' (size=${params.BATCH_JSON.length()})"
          withCentralQueue {
            def qText = fileExists(QUEUE_FILE) ? readFile(QUEUE_FILE) : '{"jobs":[],"deadLetter":[]}'
            def merged = safeMerge(qText, params.BATCH_JSON, params.SOURCE)
            writeFile file: QUEUE_FILE, text: groovy.json.JsonOutput.prettyPrint(merged)
          }
          echo "Queue updated."
        }
      }
    }

    stage('Process queue (tokens)') {
      matrix {
        axes {
          axis {
            name 'TOKEN'
            values 'agent-1','agent-2','agent-3','agent-4'
          }
        }
        agent { label "${TOKEN}" }

        stages {
          stage('Worker loop') {
            steps {
              script {
                workerLoop(env.TOKEN as String, (params.IDLE_ROUNDS ?: '24') as int)
              }
            }
          }
        }
      }
    }
  }
}

/* ============================ Worker Logic ============================ */

def workerLoop(String tokenId, int maxIdleRounds) {
  int idleRounds = 0

  while (true) {
    def jobItem = claimOne(tokenId)   // claim atomically on QUEUE_NODE

    if (jobItem == null) {
      idleRounds++
      if (idleRounds >= Math.max(1, maxIdleRounds)) {
        echo "[${tokenId}] No jobs after ${idleRounds} checks. Exiting."
        break
      }
      sleep time: 5, unit: 'SECONDS'
      continue
    }

    idleRounds = 0

    // ---- Execute outside queue critical section ----
    def jobName  = jobItem.job?.toString()
    def waitFlag = !!jobItem.wait
    def p        = buildParams(jobItem.parameters)

    echo "[${tokenId}] ▶ RUN ${jobItem.name} src=${jobItem.source} -> ${jobName} (prio=${jobItem.priority}, attempt=${jobItem.attempts}, wait=${waitFlag})"

    boolean ok = true
    String errMsg = null
    try {
      build job: jobName, wait: waitFlag, propagate: true, parameters: p
      echo "[${tokenId}] ✔ DONE ${jobItem.name}"
    } catch (e) {
      ok = false
      errMsg = e.getMessage()
      echo "[${tokenId}] ✖ FAIL ${jobItem.name} : ${errMsg}"
    }

    finalizeOne(jobItem, ok, errMsg, tokenId)  // finalize atomically on QUEUE_NODE
  }
}

/* ===================== Central queue helpers (no plugins) ===================== */

def withCentralQueue(Closure body) {
  node(QUEUE_NODE) {
    dir(QUEUE_DIR) {
      // ensure dir + file
      if (!fileExists(QUEUE_FILE)) {
        writeFile file: QUEUE_FILE, text: '{"jobs":[],"deadLetter":[]}'
      }
      withFsMutex {
        body.call()
      }
    }
  }
}

def claimOne(String tokenId) {
  def claimed = null
  withCentralQueue {
    def qText = readFile(QUEUE_FILE)
    def q = parsePlainSafe(qText) ?: [jobs:[], deadLetter:[]]
    if (!(q.jobs instanceof List)) q.jobs = []
    if (!(q.deadLetter instanceof List)) q.deadLetter = []

    // Priority desc, FIFO by receivedAt
    q.jobs.sort { a, b ->
      int pa = (a.priority ?: 0) as int
      int pb = (b.priority ?: 0) as int
      def byPrio = (pb <=> pa)
      if (byPrio != 0) return byPrio
      (a.receivedAt ?: '') <=> (b.receivedAt ?: '')
    }

    int idx = q.jobs.findIndexOf { it.status == null || it.status == 'queued' }
    if (idx != -1) {
      claimed = q.jobs[idx]
      claimed.status    = 'running'
      claimed.processor = tokenId
      claimed.attempts  = ((claimed.attempts ?: 0) as int) + 1
      writeFile file: QUEUE_FILE, text: groovy.json.JsonOutput.prettyPrint(toJsonString([jobs:q.jobs, deadLetter:q.deadLetter]))
    }
  }
  return claimed
}

def finalizeOne(def jobItem, boolean ok, String errMsg, String tokenId) {
  withCentralQueue {
    def qText = readFile(QUEUE_FILE)
    def q = parsePlainSafe(qText) ?: [jobs:[], deadLetter:[]]
    if (!(q.jobs instanceof List)) q.jobs = []
    if (!(q.deadLetter instanceof List)) q.deadLetter = []

    int idx2 = q.jobs.findIndexOf {
      it.name?.toString()   == jobItem.name?.toString() &&
      (it.receivedAt ?: '') == (jobItem.receivedAt ?: '') &&
      (it.processor ?: '')  == tokenId &&
      (it.status ?: '')     == 'running'
    }

    if (idx2 == -1) {
      echo "[${tokenId}] WARN: Claimed item not found during finalize."
      if (!ok) { (q.deadLetter as List) << (jobItem + [status:'failed', error:(errMsg ?: 'unknown')]) }
    } else {
      def running = q.jobs.remove(idx2)
      if (ok) {
        // success: drop
      } else {
        int attempts = (running.attempts ?: 1) as int
        if (attempts >= 3) {
          running.status = 'failed'
          running.error  = errMsg
          (q.deadLetter as List) << running
        } else {
          running.status    = 'queued'
          running.processor = null
          q.jobs << running   // requeue; fairness kept by resort during next claim
        }
      }
    }

    writeFile file: QUEUE_FILE, text: groovy.json.JsonOutput.prettyPrint(toJsonString([jobs:q.jobs, deadLetter:q.deadLetter]))
  }
}

/* ============================ Filesystem mutex ============================ */

def withFsMutex(Closure body) {
  // Simple mkdir-based mutex that works on the central node
  int attempts = 0
  int maxAttempts = 120
  int sleepSec = 1

  try {
    while (true) {
      int code = isUnix()
        ? sh(script: "mkdir '${LOCK_DIR}' 2>/dev/null && exit 0 || exit 1", returnStatus: true)
        : powershell(returnStatus: true, script: """
            try { New-Item -ItemType Directory -Path '${LOCK_DIR}' -ErrorAction Stop | Out-Null; exit 0 }
            catch { exit 1 }
          """.stripIndent())
      if (code == 0) break
      attempts++
      if (attempts >= maxAttempts) error "Could not acquire queue mutex at ${pwd()}/${LOCK_DIR}"
      sleep time: sleepSec, unit: 'SECONDS'
    }

    body.call()

  } finally {
    if (isUnix()) {
      sh script: "rm -rf '${LOCK_DIR}' || true"
    } else {
      powershell script: "Remove-Item -LiteralPath '${LOCK_DIR}' -Force -Recurse -ErrorAction SilentlyContinue"
    }
  }
}

/* ============================ JSON & Params ============================ */

def buildParams(List plist) {
  def m = [:]
  (plist ?: []).each { kv ->
    if (kv?.name) m[kv.name.toString()] = (kv.value == null ? '' : kv.value.toString())
  }
  return [
    string(name: 'PARAM1', value: m['PARAM1'] ?: ''),
    string(name: 'PARAM2', value: m['PARAM2'] ?: ''),
    string(name: 'PARAM3', value: m['PARAM3'] ?: ''),
    string(name: 'PARAM4', value: m['PARAM4'] ?: '')
  ]
}

@NonCPS
def safeMerge(String existingText, String batchText, String source) {
  def existing = parsePlainSafe(existingText) ?: [jobs: [], deadLetter: []]
  if (!(existing.jobs instanceof List)) existing.jobs = []
  if (!(existing.deadLetter instanceof List)) existing.deadLetter = []

  def batch = parsePlainSafe(batchText) ?: [jobs: []]
  def now = new Date().format("yyyy-MM-dd'T'HH:mm:ssXXX")

  (batch.jobs ?: []).each { j ->
    def item = toPlain(j) ?: [:]
    if (!(item.parameters instanceof List)) item.parameters = []
    item.source     = source?.toString()
    item.receivedAt = now
    item.status     = 'queued'
    item.attempts   = 0
    existing.jobs << item
  }

  return groovy.json.JsonOutput.toJson(existing)
}

@NonCPS
def parsePlainSafe(String jsonText) {
  if (!jsonText) return null
  def t = jsonText.trim()
  if (t.length() == 0) return null
  try {
    def p = new groovy.json.JsonSlurper().parseText(t)
    return toPlain(p)
  } catch (Throwable ignored) {
    return null
  }
}

@NonCPS
def toPlain(Object o) {
  if (o instanceof Map)  { def m = [:]; o.each { k,v -> m[(k?.toString())] = toPlain(v) }; return m }
  if (o instanceof List) { def l = [];  o.each { v -> l << toPlain(v) }; return l }
  return o
}

@NonCPS
def toJsonString(Object o) { groovy.json.JsonOutput.toJson(o) }
